{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c812183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19228da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Shabbir\\\\Desktop\\\\YT_Prac\\\\Text-Summarization-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb47b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f125f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Shabbir\\\\Desktop\\\\YT_Prac\\\\Text-Summarization-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8570aeb",
   "metadata": {},
   "source": [
    "# Config.yaml and Entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c55bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636434a",
   "metadata": {},
   "source": [
    "# Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ecaee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextSummarizer.constants import *\n",
    "from TextSummarizer.utils.common import create_directories, read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087692b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class configurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=None,\n",
    "        params_filepath=None,\n",
    "    ):\n",
    "        if config_filepath is None:\n",
    "            config_filepath = CONFIG_FILE_PATH\n",
    "        if params_filepath is None:\n",
    "            params_filepath = PARAMS_FILE_PATH\n",
    "            \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL = config.source_URL,\n",
    "            local_data_file = config.local_data_file,\n",
    "            unzip_dir = config.unzip_dir,\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a16944",
   "metadata": {},
   "source": [
    "# Components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2635f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from TextSummarizer.logging import logger\n",
    "from TextSummarizer.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ccdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def download_file(self):\n",
    "        \"\"\"Download data.zip from source_URL using safe streaming.\"\"\"\n",
    "        url = self.config.source_URL\n",
    "        out_path = Path(self.config.local_data_file)\n",
    "        tmp_path = out_path.with_suffix(out_path.suffix + \".part\")\n",
    "\n",
    "        # if file exists, skip download\n",
    "        if out_path.exists():\n",
    "            logger.info(f\"File already exists of size: {get_size(out_path)}\")\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Downloading from: {url}\")\n",
    "\n",
    "        try:\n",
    "            with requests.get(url, stream=True, timeout=60) as r:\n",
    "                r.raise_for_status()  # throws error for HTTP != 200\n",
    "\n",
    "                out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # write to .part temporary file first\n",
    "                with open(tmp_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "            # ensure non-zero file\n",
    "            if tmp_path.stat().st_size == 0:\n",
    "                raise RuntimeError(\"Downloaded file is empty (0 bytes).\")\n",
    "\n",
    "            # move .part → final filename\n",
    "            tmp_path.replace(out_path)\n",
    "\n",
    "            logger.info(\n",
    "                f\"{out_path} downloaded successfully! \"\n",
    "                f\"Size: {get_size(out_path)}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Download failed: {e}\")\n",
    "            if tmp_path.exists():\n",
    "                tmp_path.unlink()  # remove partial file\n",
    "            raise e\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"Safely extract ZIP file member-by-member with clear error logging.\"\"\"\n",
    "        zip_path = Path(self.config.local_data_file)\n",
    "        extract_dir = Path(self.config.unzip_dir)\n",
    "\n",
    "        if not zip_path.exists():\n",
    "            logger.error(f\"ZIP file not found at: {zip_path}\")\n",
    "            raise FileNotFoundError(f\"{zip_path} does not exist\")\n",
    "\n",
    "        logger.info(f\"Extracting ZIP: {zip_path}\")\n",
    "\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "                members = z.namelist()\n",
    "                logger.info(f\"Total files/folders in ZIP: {len(members)}\")\n",
    "\n",
    "                for i, member in enumerate(members, start=1):\n",
    "                    target = extract_dir / member\n",
    "\n",
    "                    # Create directories as needed\n",
    "                    if member.endswith(\"/\") or member.endswith(\"\\\\\"):\n",
    "                        target.mkdir(parents=True, exist_ok=True)\n",
    "                        logger.debug(f\"[{i}/{len(members)}] Dir created: {member}\")\n",
    "                        continue\n",
    "\n",
    "                    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    # Extract file in chunks\n",
    "                    with z.open(member) as src, open(target, \"wb\") as dst:\n",
    "                        while True:\n",
    "                            chunk = src.read(1024 * 64)  # 64 KB\n",
    "                            if not chunk:\n",
    "                                break\n",
    "                            dst.write(chunk)\n",
    "                        dst.flush()\n",
    "                        os.fsync(dst.fileno())\n",
    "\n",
    "                    logger.debug(f\"[{i}/{len(members)}] Extracted: {member}\")\n",
    "\n",
    "            logger.info(f\"Extraction completed successfully → {extract_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error while extracting ZIP: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ded95d",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3667a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-23 18:13:19,079: INFO: common]: YAML file: config\\config.yaml loaded successfully\n",
      "[2025-11-23 18:13:19,080: INFO: common]: YAML file: params.yaml loaded successfully\n",
      "[2025-11-23 18:13:19,081: INFO: common]: Created directory at: artifacts\n",
      "[2025-11-23 18:13:19,082: INFO: common]: Created directory at: artifacts/data_ingestion\n",
      "[2025-11-23 18:13:19,084: INFO: 1713455135]: Downloading from: https://github.com/entbappy/Branching-tutorial/raw/refs/heads/master/samsumdata.zip\n",
      "[2025-11-23 18:13:22,564: INFO: 1713455135]: artifacts\\data_ingestion\\data.zip downloaded successfully! Size: 23073.25 KB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = configurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textSum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
